"""
æŸ¥è¯¢æ‰©å±•æ¨¡å— - Phase 1ä¼˜åŒ–
é€šè¿‡åŒä¹‰è¯æ‰©å±•å’Œå¤šæŸ¥è¯¢èåˆæå‡æœç´¢å‡†ç¡®ç‡
"""

import jieba
from typing import List, Dict
import logging

logger = logging.getLogger(__name__)


class QueryExpander:
    """æŸ¥è¯¢æ‰©å±•å™¨ - æå‡æœç´¢å¬å›ç‡"""
    
    def __init__(self):
        # ä¸­æ–‡åŒä¹‰è¯è¯å…¸
        self.synonyms = {
            # é¢œè‰²ç›¸å…³
            "è“è‰²": ["å¤©è“", "æ¹›è“", "è”šè“", "é’è“"],
            "çº¢è‰²": ["å¤§çº¢", "æœ±çº¢", "crimson"],
            "ç»¿è‰²": ["ç¿ ç»¿", "ç¢§ç»¿", "é’ç»¿"],
            "é»„è‰²": ["é‡‘é»„", "é¹…é»„", "å«©é»„"],
            
            # å»ºç­‘ç›¸å…³
            "å»ºç­‘": ["æˆ¿å±‹", "å¤§æ¥¼", "å»ºç­‘ç‰©", "æ¥¼æˆ¿", "æ¥¼å®‡"],
            "æˆ¿å­": ["æˆ¿å±‹", "æ°‘å±…", "ä½å®…"],
            "é«˜æ¥¼": ["å¤§æ¥¼", "æ‘©å¤©å¤§æ¥¼", "é«˜å±‚å»ºç­‘"],
            
            # äººç‰©ç›¸å…³
            "äººç‰©": ["äºº", "äººåƒ", "è‚–åƒ", "é¢å­”", "äººå£«"],
            "äºº": ["äººç‰©", "äººå‘˜", "äººå£«"],
            
            # è‡ªç„¶æ™¯è§‚
            "å¤©ç©º": ["è‹ç©¹", "å¤©é™…", "äº‘å¤©"],
            "å¤§æµ·": ["æµ·æ´‹", "æµ·", "å¤§æ´‹"],
            "å±±": ["å±±å³°", "é«˜å±±", "å±±å²³", "å±±è„‰"],
            "æ ‘": ["æ ‘æœ¨", "ä¹”æœ¨", "æ—æœ¨"],
            
            # åŠ¨ç‰©ç›¸å…³
            "çŒ«": ["çŒ«å’ª", "å°çŒ«", "å–µæ˜Ÿäºº"],
            "ç‹—": ["ç‹—ç‹—", "çŠ¬", "æ±ªæ˜Ÿäºº"],
            
            # é£Ÿç‰©ç›¸å…³
            "é£Ÿç‰©": ["ç¾é£Ÿ", "é£Ÿå“", "åƒçš„"],
            "ç¾é£Ÿ": ["é£Ÿç‰©", "ä½³è‚´", "èœè‚´"],
        }
        
        # åœç”¨è¯
        self.stopwords = {"çš„", "æ˜¯", "åœ¨", "äº†", "å’Œ", "ä¸", "æˆ–", "ç­‰", "å•Š", "å‘¢", "å—"}
        
        logger.info("âœ… æŸ¥è¯¢æ‰©å±•å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def expand_query(self, query: str) -> List[str]:
        """
        æ‰©å±•æŸ¥è¯¢  
        
        Args:
            query: åŸå§‹æŸ¥è¯¢å­—ç¬¦ä¸²
            
        Returns:
            æ‰©å±•åçš„æŸ¥è¯¢åˆ—è¡¨
        """
        expanded_queries = [query]  # å§‹ç»ˆåŒ…å«åŸå§‹æŸ¥è¯¢
        
        # 1. åŒä¹‰è¯æ‰©å±•
        for word, synonyms in self.synonyms.items():
            if word in query:
                for syn in synonyms[:2]:  # é™åˆ¶æ¯ä¸ªè¯æœ€å¤š2ä¸ªåŒä¹‰è¯
                    expanded_query = query.replace(word, syn)
                    if expanded_query not in expanded_queries:
                        expanded_queries.append(expanded_query)
        
        # 2. åˆ†è¯æ‰©å±• - æå–å…³é”®è¯
        tokens = list(jieba.cut(query))
        keywords = [t for t in tokens if t not in self.stopwords and len(t) > 1]
        
        # æ·»åŠ ä¸»è¦å…³é”®è¯ä½œä¸ºç‹¬ç«‹æŸ¥è¯¢
        for keyword in keywords[:2]:  # æœ€å¤šæ·»åŠ 2ä¸ªå…³é”®è¯
            if keyword != query and keyword not in expanded_queries:
                expanded_queries.append(keyword)
        
        logger.info(f"ğŸ“ æŸ¥è¯¢æ‰©å±•: '{query}' â†’ {len(expanded_queries)} ä¸ªæŸ¥è¯¢")
        logger.debug(f"   æ‰©å±•æŸ¥è¯¢: {expanded_queries}")
        
        return expanded_queries
    
    def add_synonym(self, word: str, synonyms: List[str]):
        """åŠ¨æ€æ·»åŠ åŒä¹‰è¯"""
        if word not in self.synonyms:
            self.synonyms[word] = []
        self.synonyms[word].extend(synonyms)
        logger.info(f"âœ… æ·»åŠ åŒä¹‰è¯: {word} â†’ {synonyms}")
